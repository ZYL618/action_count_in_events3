{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5443207d",
   "metadata": {},
   "source": [
    "# 曼哈顿压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fdf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算两个坐标的曼哈顿距离\n",
    "def compute_distance(x1,y1,x2,y2):\n",
    "    return abs(x1-x2),abs(y1-y2)\n",
    "# 通过与下一个事件点比较从而判断当前事件点是否为噪声\n",
    "def is_noise(row,next_event,delta):\n",
    "    # 当前点的下一个点距离太远且count==1，则当前点被认为是噪声点\n",
    "    x_dis,y_dis = compute_distance(row[1],row[2],next_event[1],next_event[2])\n",
    "    # 当前事件点是噪声，跳过不录入\n",
    "    if x_dis > delta or y_dis > delta:\n",
    "        # 是噪声点\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# 将聚合点写入CSV文件\n",
    "def write_to_csv(temp_x,temp_y,count,path):\n",
    "    pd.DataFrame(data=[[temp_x/count,temp_y/count]]).to_csv(path,\n",
    "                                                   mode='a',header=False,index=False)\n",
    "# 选择聚类起始点\n",
    "def select_start_point(df,delta):\n",
    "    for index,row in df.iterrows():\n",
    "        d1,d2 = compute_distance(row[1],row[2],df['x'][index+1],df['y'][index+1])\n",
    "        if d1 <= delta and d2 < delta:\n",
    "            # 说明当前点周围有其他点，大概率不是噪声点\n",
    "            return index,row      \n",
    "# 曼哈顿压缩\n",
    "def compress_by_Manhattan(file_name,class_num,delta=5,count_margin=100,nature_flag=True):\n",
    "    file_path = None\n",
    "    to_file_path = None\n",
    "    # 自然数据路径\n",
    "    if nature_flag:\n",
    "        file_path = f'../../event_csv/split_data/class{class_num}/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/{file_name}'\n",
    "    # 人工合成数据路径\n",
    "    else:\n",
    "        file_path = f'../../event_csv/split_data/artificial/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/{file_name}'  \n",
    "    \n",
    "#     df = pd.read_csv(file_path,skiprows=1)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 曼哈顿距离比较对象【最开始的点可能是噪声点】\n",
    "    start,row = select_start_point(df,delta)\n",
    "    # row[0]是时间戳列\n",
    "    baseline_x = row[1]\n",
    "    baseline_y = row[2]\n",
    "    \n",
    "    # 待写入的曼哈顿距离\n",
    "    temp_x = 0\n",
    "    temp_y = 0\n",
    "    count = 0\n",
    "    pd.DataFrame(data=[['x','y']]).to_csv(to_file_path,mode='w',header=False,index=False)\n",
    "    # 遍历每一行\n",
    "    for index,row in df.iterrows():\n",
    "        if index < start:\n",
    "            continue\n",
    "        # 在曼哈顿距离内，聚为一个点，取平均值\n",
    "        x_dis,y_dis = compute_distance(baseline_x,baseline_y,row[1],row[2])\n",
    "        # 最多聚焦 count_margin 个点\n",
    "        if x_dis <= delta and y_dis <= delta and count < count_margin:\n",
    "            # 平均值的分母\n",
    "            count = count + 1\n",
    "            temp_x = temp_x + row[1]\n",
    "            temp_y = temp_y + row[2]\n",
    "        else:\n",
    "            # 来到最后一个事件点位置\n",
    "            if index + 1 >= df.shape[0]:\n",
    "                if count > 1:\n",
    "                    write_to_csv(temp_x,temp_y,count,to_file_path)\n",
    "                break\n",
    "            next_event = df.iloc[index+1]\n",
    "            # 当前点的下一个点距离太远且count==1，则当前点被认为是噪声点\n",
    "            if count == 1 and is_noise(row,next_event,delta):\n",
    "                # 当前事件点是噪声，跳过不录入\n",
    "                continue\n",
    "            write_to_csv(temp_x,temp_y,count,to_file_path)\n",
    "            baseline_x = row[1]\n",
    "            baseline_y = row[2]\n",
    "            temp_x = row[1]\n",
    "            temp_y = row[2]\n",
    "            count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da50de",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a6ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction_PCA(file_name,class_num,nature_flag=True):\n",
    "    df = None\n",
    "    to_file_path = None\n",
    "    if nature_flag:\n",
    "        # 时空过滤之后的数据\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/class{class_num}/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/{file_name}'\n",
    "    else:\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/articicial/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/{file_name}'\n",
    "    # PCA主成分分析，只要第一维\n",
    "    data = PCA_method(df)\n",
    "    pd.DataFrame(data,columns=['value']).to_csv(to_file_path,mode='w',header=True,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f26d70",
   "metadata": {},
   "source": [
    "# 均值压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4e8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_by_mean(file_name,class_num,chunksize=100,nature_flag=True):\n",
    "    file_path = None\n",
    "    to_file_path = None\n",
    "    if nature_flag:\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "    else:\n",
    "        # 人工合成数据路径\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "\n",
    "    df = pd.read_csv(file_path,chunksize=chunksize,usecols=['value'])\n",
    "    pd.DataFrame(data=[['value']]).to_csv(to_file_path,mode='w',header=False,index=False)\n",
    "    for chunk in df:\n",
    "        temp = pd.DataFrame([chunk.mean()])\n",
    "        temp.to_csv(to_file_path,index=False,header=False,mode='a')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d228b4a",
   "metadata": {},
   "source": [
    "# 二者整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbbb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 波形平滑\n",
    "def distance_mean_meanline(file_name,class_num=-1,delta=5,count=100,mean_count=100,nature_flag=True):\n",
    "    # 曼哈顿距离压缩\n",
    "    compress_by_Manhattan(file_name,class_num,delta=delta,count_margin=count,nature_flag=nature_flag)\n",
    "    # PCA + HP滤波\n",
    "    dimensionality_reduction_PCA(file_name,class_num,nature_flag=nature_flag)\n",
    "    # 平均值压缩\n",
    "    compress_by_mean(file_name,class_num,chunksize=mean_count,nature_flag=nature_flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
