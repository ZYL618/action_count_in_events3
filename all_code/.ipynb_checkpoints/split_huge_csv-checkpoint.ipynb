{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfaabc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# 读取训练集文件名\n",
    "train_file_names = np.load('train_file_names.npy')\n",
    "test_file_names = np.load('test_file_names.npy')\n",
    "file_names = np.load('file_names.npy')\n",
    "labels_file_names = np.load('labels_names.npy')\n",
    "prefix_path = '../events_csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcbe62",
   "metadata": {},
   "source": [
    "# 数据清洗\n",
    "> 作者给出的事件文件时间戳意义不明，经过如下清洗后，我们能够顺利将标签中的时间戳与动作真正时间戳对应上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c38347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将第一个事件发生的时间戳置0，同时除去噪声点\n",
    "def data_clean(file_path,new_file_path,start_time):\n",
    "    reader = pd.read_csv(file_path,header=1,usecols=['timestamp', 'x','y'],chunksize=10000)\n",
    "    cols = pd.DataFrame(data=[['timestamp','x','y']])\n",
    "    # 将列名写入csv文件\n",
    "    cols.to_csv(new_file_path,header=False,index=False)    \n",
    "    # 每次读取 10000 行，chunk是DataFrame\n",
    "    for chunk in reader:\n",
    "        chunk.iloc[:,0] = chunk.iloc[:,0] - start_time\n",
    "        real_index = 0\n",
    "        # 当前块的最后一行时间戳小于0，说明往下的数据都是噪声点，可以抛弃\n",
    "        if chunk.iloc[-1,0] < 0:\n",
    "            # 此块行索引之前的元素进行保存，之后的元素抛弃\n",
    "            while chunk.iloc[real_index,0] >= 0:\n",
    "                real_index = real_index + 1\n",
    "            chunk.iloc[:real_index,:].to_csv(new_file_path,mode='a',header=False,index=False)\n",
    "            break\n",
    "        else:\n",
    "            # 所有事件点都是有用的，写入清洗文件中\n",
    "            chunk.to_csv(new_file_path,mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb93682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对训练集数据清洗\n",
    "for name in train_file_names:\n",
    "    file_path = prefix_path + name\n",
    "    start_time = pd.read_csv(file_path,header=1,usecols=['timestamp'],nrows=1).iloc[0,0]\n",
    "    # 数据清洗并写入到新文件中\n",
    "    data_clean(file_path,'../events_csv_clean/'+name,start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9715bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集数据清洗\n",
    "for name in test_file_names:\n",
    "    file_path = prefix_path + name\n",
    "    start_time = pd.read_csv(file_path,header=1,usecols=['timestamp'],nrows=1).iloc[0,0]\n",
    "    # 数据清洗并写入到新文件中\n",
    "    data_clean(file_path,'../events_csv_clean/'+name,start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19ea5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签数据进行清洗\n",
    "for name in labels_file_names:\n",
    "    cols = pd.DataFrame(data=[['class','startTime_usec','endTime_usec']])\n",
    "    # 将列名写入csv文件\n",
    "    cols.to_csv('../labels_clean/'+name,header=False,index=False)\n",
    "    label = pd.read_csv('../labels/'+name)\n",
    "    start_time = label.iloc[0,1]\n",
    "    label.iloc[:,1] = label.iloc[:,1] - start_time\n",
    "    label.iloc[:,2] = label.iloc[:,2] - start_time\n",
    "    label.to_csv('../labels_clean/'+name,mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639610a",
   "metadata": {},
   "source": [
    "# 按照标签对对应事件进行切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a73a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每个class文件提前准备好列名，后续可专注于处理数据\n",
    "cols = pd.DataFrame(data=[['timestamp','x','y']])\n",
    "# 总共有 11 类【class1~class11】\n",
    "for i in range(1,12):\n",
    "    for name in file_names:\n",
    "        cols.to_csv('../split_data/class'+str(i)+'/'+name,mode='w',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6e5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class_info(labels,row_index):\n",
    "    class_num = labels.iloc[row_index,0]\n",
    "    start_time = labels.iloc[row_index,1]\n",
    "    end_time = labels.iloc[row_index,2]\n",
    "    return class_num,start_time,end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2c79bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label是切割文件DF，data是待切割的文件完整路径\n",
    "def split_by_timestamp(labels,data_path,data_name):\n",
    "    row_index = 12\n",
    "    # 标签中的类别，开始时间与结束时间\n",
    "    class_num,start_time,end_time = update_class_info(labels,row_index)\n",
    "    # 块小一些比较保险，避免一个块跨越多个事件\n",
    "    data_reader = pd.read_csv(data_path,chunksize=200)\n",
    "    # 标志位\n",
    "    flag_count = 0 \n",
    "    for chunk in data_reader:\n",
    "        # 当前块开始和结束时间\n",
    "        start = chunk.iloc[0,0]\n",
    "        end = chunk.iloc[-1,0]\n",
    "        if start < start_time and end > start_time and end < end_time:\n",
    "            # 寻找刚刚大于start_time的事件点开始写入\n",
    "            real_index = 0\n",
    "            while chunk.iloc[real_index,0] < start_time:\n",
    "                real_index = real_index + 1\n",
    "            if flag_count == 0:\n",
    "                # 以index为分界线，全部数据都写入\n",
    "                chunk.iloc[real_index:,:].to_csv(f'../split_data/class{class_num}/{data_name}',mode='a',header=False,index=False)\n",
    "            else:\n",
    "                chunk.iloc[real_index:,:].to_csv(f'../split_data/class{class_num}/{data_name[:-4]}{flag_count}.csv',mode='a',header=False,index=False)\n",
    "        elif start >= start_time and end <= end_time :\n",
    "            if flag_count == 0:\n",
    "                # 以index为分界线，全部数据都写入\n",
    "                chunk.to_csv(f'../split_data/class{class_num}/{data_name}',mode='a',header=False,index=False)\n",
    "            else:\n",
    "                chunk.to_csv(f'../split_data/class{class_num}/{data_name[:-4]}{flag_count}.csv',mode='a',header=False,index=False)  \n",
    "        elif start > start_time and start < end_time and end > end_time:\n",
    "            real_index = 0\n",
    "            while chunk.iloc[real_index,0] < end_time:\n",
    "                real_index = real_index + 1 \n",
    "            if flag_count == 0:\n",
    "                # 以index为分界线，全部数据都写入\n",
    "                chunk.iloc[:real_index,:].to_csv(f'../split_data/class{class_num}/{data_name}',mode='a',header=False,index=False)\n",
    "            else:\n",
    "                chunk.iloc[:real_index,:].to_csv(f'../split_data/class{class_num}/{data_name[:-4]}{flag_count}.csv',mode='a',header=False,index=False)\n",
    "            row_index = row_index + 1\n",
    "            break\n",
    "            # 超过标签索引，丢弃\n",
    "            if row_index >= labels.shape[0]:\n",
    "                break\n",
    "            class_num,start_time,end_time = update_class_info(labels,row_index)\n",
    "            # 说明出现了重复类\n",
    "            if class_num == labels.iloc[row_index-1,0]:\n",
    "                cols = pd.DataFrame(data=[['timestamp','x','y']])\n",
    "                flag_count = flag_count + 1\n",
    "                cols.to_csv(f'../split_data/class{class_num}/{data_name[:-4]}{flag_count}.csv',mode='w',header=False,index=False)\n",
    "            else:\n",
    "                # 初始化\n",
    "                flag_count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "851a560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时遍历标签和数据的csv\n",
    "# 标签每次读取一行，记录有class,start,end\n",
    "# 数据每次读取chunk，如果时间点在[start,end]之间，则将对应csv文件存入class文件夹中\n",
    "# label是标签的文件名,data_name是数据的文件名\n",
    "for label_name,data_name in zip(labels_file_names,file_names):\n",
    "    label_data = pd.read_csv('../labels_clean/'+label_name)\n",
    "    split_by_timestamp(label_data,'../events_csv_clean/'+data_name,data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bf71106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_data = pd.read_csv('../labels_clean/user25_fluorescent_labels.csv')\n",
    "# label_data2 = pd.read_csv('../labels_clean/user04_fluorescent_led_labels.csv')\n",
    "# label_data3 = pd.read_csv('../labels_clean/user02_natural_labels.csv')\n",
    "# label_data4 = pd.read_csv('../labels_clean/user14_fluorescent_led_labels.csv')\n",
    "# label_data5 = pd.read_csv('../labels_clean/user01_natural_labels.csv')\n",
    "# label_data6 = pd.read_csv('../labels_clean/user07_led_labels.csv')\n",
    "# label_data7 = pd.read_csv('../labels_clean/user09_fluorescent_labels.csv')\n",
    "# label_data8 = pd.read_csv('../labels_clean/user24_fluorescent_led_labels.csv')\n",
    "# label_data9 = pd.read_csv('../labels_clean/user22_led_labels.csv')\n",
    "label_data10 = pd.read_csv('../labels_clean/user12_fluorescent_led_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "728062c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_by_timestamp(label_data,'../events_csv_clean/user25_fluorescent.csv','user25_fluorescent.csv')\n",
    "# split_by_timestamp(label_data2,'../events_csv_clean/user04_fluorescent_led.csv','user04_fluorescent_led.csv')\n",
    "# split_by_timestamp(label_data3,'../events_csv_clean/user02_natural.csv','user02_natural.csv')\n",
    "# split_by_timestamp(label_data4,'../events_csv_clean/user14_fluorescent_led.csv','user14_fluorescent_led.csv')\n",
    "# split_by_timestamp(label_data5,'../events_csv_clean/user01_natural.csv','user01_natural.csv')\n",
    "# split_by_timestamp(label_data6,'../events_csv_clean/user07_led.csv','user07_led.csv')\n",
    "# split_by_timestamp(label_data7,'../events_csv_clean/user09_fluorescent.csv','user09_fluorescent.csv')\n",
    "# split_by_timestamp(label_data8,'../events_csv_clean/user24_fluorescent_led.csv','user24_fluorescent_led.csv')\n",
    "# split_by_timestamp(label_data9,'../events_csv_clean/user22_led.csv','user22_led.csv')\n",
    "split_by_timestamp(label_data10,'../events_csv_clean/user12_fluorescent_led.csv','user12_fluorescent_led.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c1f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
